---
title: "ðŸŽ¶ Project ImproVision"
excerpt: "Developing human-robot interaction systems for musical settings, focusing on nonverbal communication between musicians and robotic conducting agents."
#<br/><img src='/images/500x300.png'>
collection: portfolio
---

## Overview
Project ImproVision investigates the future of human-robot interaction in musical performance settings. We're developing a robotic conducting system that can interpret visual cues from musicians and respond with appropriate conducting gestures in real-time.

<img src='/images/ImproVision_setup.png'>

## Technical Implementation
- Developed a camera-based robotic interface using Python for gesture detection
- Implemented real-time pitch analysis systems using C++
- Created an integrated system enabling dynamic real-time interaction between musicians and the robotic conductor

<img src='/images/ImproVision_demo.png'>

<img src='/images/PTZ_cam.png'>

## Key Achievements
- Led the development of the gesture recognition system
- Contributed to two research papers
- Check out our presentation from the ArtsIT Conference [here](https://drive.google.com/file/d/1IUlFXF93GqRicorRfSUL2slx2Da_3QsB/view?usp=sharing)!

## Publications
1. "Creativity and Visual Communication from Machine to Musician: Sharing a Score through a Robotic Camera" - [EAI ArtsIT Conference 2024](https://artsit.eai-conferences.org/2024/)
2. "ImproVision Equilibrium: Towards Multimodal Musical Human-Machine Interaction" (Under review)

## Future Directions
We have multiple "interactive musical games" right now, which I'm working on combining into a full system demo in the coming months!
